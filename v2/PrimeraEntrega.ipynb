{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T11:14:56.074339700Z",
     "start_time": "2024-10-25T11:14:55.058884700Z"
    }
   },
   "id": "64956a6e85403461"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inicialización de Pesos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45a5a3c119796f4c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-25T11:14:19.686977Z",
     "start_time": "2024-10-25T11:14:19.651305300Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_weights(layer_sizes):\n",
    "    \"\"\"\n",
    "    Inicializa los pesos y biases para una red de múltiples capas.\n",
    "\n",
    "    Parameters:\n",
    "        layer_sizes : list of int\n",
    "            Lista donde cada elemento es el número de neuronas de cada capa (incluyendo capa de entrada y de salida).\n",
    "\n",
    "    Returns:\n",
    "        weights : list of np.array\n",
    "            Lista de matrices de pesos para cada capa.\n",
    "        biases : list of np.array\n",
    "            Lista de vectores de bias para cada capa.\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    # Inicializamos los pesos y biases entre cada capa de la red\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        W = np.random.randn(layer_sizes[i - 1], layer_sizes[i]) * 0.01\n",
    "        b = np.zeros((1, layer_sizes[i]))\n",
    "        weights.append(W)\n",
    "        biases.append(b)\n",
    "\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00146973 -0.00410816  0.01000724]\n",
      " [-0.00521095  0.00777858 -0.01853591]\n",
      " [ 0.01106299  0.01062594 -0.00285421]\n",
      " [-0.00242291 -0.01188509 -0.01484589]\n",
      " [ 0.02448822  0.00580446 -0.00066426]\n",
      " [-0.01063403 -0.0023246  -0.01287589]\n",
      " [-0.00833861  0.0097587   0.01816757]\n",
      " [-0.02004078  0.0012141  -0.00641758]]\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [4, 10, 8, 3] \n",
    "weights, biases = initialize_weights(layer_sizes)\n",
    "print(weights[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T11:18:58.759772900Z",
     "start_time": "2024-10-25T11:18:58.712446400Z"
    }
   },
   "id": "85e872d523d714c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Funciones de Activación"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e588983c3aacec2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ReLu"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3d38a1f64f5f0a9"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Función de activación ReLU\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Derivada de ReLU para backpropagation\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T11:27:24.581187300Z",
     "start_time": "2024-10-25T11:27:24.568674900Z"
    }
   },
   "id": "4e7d2c382685d74c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sigmoide"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f65db2965687bc8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e07652db9b8de99e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Softmax"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52928dd5d0a5c737"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Evita overflow numérico\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T11:27:38.366821200Z",
     "start_time": "2024-10-25T11:27:38.325553400Z"
    }
   },
   "id": "a3f1a1fba5b3fa57"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T11:21:35.292508400Z",
     "start_time": "2024-10-25T11:21:29.735631600Z"
    }
   },
   "id": "9e9e8c17b79b074f"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T11:21:40.771409500Z",
     "start_time": "2024-10-25T11:21:40.739993600Z"
    }
   },
   "id": "fcf51f8fc20e3614"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Forward Propagation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "855b4c01a729c6fb"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def forward_propagation(X, weights, biases): # , activations\n",
    "    \"\"\"\n",
    "    Realiza la propagación hacia adelante en una red de múltiples capas.\n",
    "\n",
    "    Parameters:\n",
    "        X : np.array\n",
    "            Entrada de la red.\n",
    "        weights : list of np.array\n",
    "            Lista de matrices de pesos para cada capa.\n",
    "        biases : list of np.array\n",
    "            Lista de vectores de bias para cada capa.\n",
    "        activations : list of functions\n",
    "            Funciones de activación para cada capa.\n",
    "\n",
    "    Returns:\n",
    "        activations_list : list of np.array\n",
    "            Lista de activaciones para cada capa.\n",
    "        zs : list of np.array\n",
    "            Lista de valores z (pre-activación) para cada capa.\n",
    "    \"\"\"\n",
    "    activations_list = [X]\n",
    "    zs = []\n",
    "    activation = X\n",
    "\n",
    "    # Propagación hacia adelante para todas las capas menos la última # Los z deberían ser los a del profe y viceversa\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = np.dot(activation, weights[i]) + biases[i]\n",
    "        zs.append(z)\n",
    "        activation = relu(z)\n",
    "        activations_list.append(activation)\n",
    "\n",
    "    # Última capa con softmax\n",
    "    z = np.dot(activation, weights[-1]) + biases[-1]\n",
    "    zs.append(z)\n",
    "    activation = softmax(z)\n",
    "    activations_list.append(activation)\n",
    "\n",
    "    return activations_list, zs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T11:26:30.910528100Z",
     "start_time": "2024-10-25T11:26:30.891480Z"
    }
   },
   "id": "5d3f3f3f5c1fd74e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activations_list, zs = forward_propagation(X, weights, biases)\n",
    "print(zs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "713e77b7468789f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Función de Coste"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "780b37aff8c47eee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_cost(Y_pred, Y_true):\n",
    "    \"\"\"\n",
    "    Calcula el costo usando la entropía cruzada categórica.\n",
    "\n",
    "    Parameters:\n",
    "        Y_pred : np.array\n",
    "            Salidas predichas de la red (después de softmax).\n",
    "        Y_true : np.array\n",
    "            Etiquetas en formato one-hot.\n",
    "\n",
    "    Returns:\n",
    "        cost : float\n",
    "            El valor del costo (entropía cruzada categórica).\n",
    "    \"\"\"\n",
    "    m = Y_true.shape[0]\n",
    "    cost = -np.sum(Y_true * np.log(Y_pred)) / m\n",
    "    return cost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cc0be06ecf8ee49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backward Propagation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88202478062a92b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def backward_propagation(Y, weights, biases, activations_list, zs, activation_derivatives):\n",
    "    \"\"\"\n",
    "    Realiza la retropropagación en una red de múltiples capas para calcular los gradientes.\n",
    "\n",
    "    Parameters:\n",
    "        Y : np.array\n",
    "            Etiquetas en formato one-hot.\n",
    "        weights : list of np.array\n",
    "            Lista de matrices de pesos para cada capa.\n",
    "        biases : list of np.array\n",
    "            Lista de vectores de bias para cada capa.\n",
    "        activations_list : list of np.array\n",
    "            Lista de activaciones para cada capa.\n",
    "        zs : list of np.array\n",
    "            Lista de valores z (pre-activación) para cada capa.\n",
    "        activation_derivatives : list of functions\n",
    "            Derivadas de las funciones de activación para cada capa.\n",
    "\n",
    "    Returns:\n",
    "        nabla_b : list of np.array\n",
    "            Gradientes de los biases para cada capa.\n",
    "        nabla_w : list of np.array\n",
    "            Gradientes de los pesos para cada capa.\n",
    "    \"\"\"\n",
    "    num_layers = len(weights)\n",
    "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "\n",
    "    # Cálculo del error en la capa de salida\n",
    "    delta = activations_list[-1] - Y        # Es lo mismo que usar entropía cruzada\n",
    "    nabla_b[-1] = delta\n",
    "    nabla_w[-1] = np.dot(activations_list[-2].T, delta) # Creo que hay que quitarlo / Y.shape[0]\n",
    "\n",
    "    # Retropropagación a través de las capas ocultas\n",
    "    for l in range(2, num_layers + 1):\n",
    "        z = zs[-l]\n",
    "        sp = activation_derivatives[-l](z)\n",
    "        delta = np.dot(delta, weights[-l + 1].T) * sp\n",
    "        nabla_b[-l] = delta\n",
    "        nabla_w[-l] = np.dot(activations_list[-l - 1].T, delta) # Esto también / Y.shape[0]\n",
    "\n",
    "    return nabla_b, nabla_w"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f79a384ca738657"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
